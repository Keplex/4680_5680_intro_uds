{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U googlemaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import googlemaps\n",
    "import seaborn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import MTA Turnstile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta = pd.DataFrame(data=None)\n",
    "mta_root = \"Data/MTA/2021_Weekly_Raw/\"\n",
    "for item in os.listdir(mta_root):\n",
    "    if not item.startswith('.') and os.path.isfile(os.path.join(mta_root, item)):\n",
    "        mta = pd.concat([mta, pd.read_csv('Data/MTA/2021_Weekly_Raw/'+item)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta.columns = ['C/A', 'Unit', 'Scp', 'Station', 'Linename', 'Division', 'Date', 'Time', 'Desc', 'Entries', 'Exits']\n",
    "mta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning: Processing Exit/Entrance Numbers and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_convert(date_to_convert):\n",
    "     return time.mktime(datetime.strptime(date_to_convert, \"%m/%d/%Y %H:%M:%S\").timetuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = mta['Date'] + ' ' + mta['Time']\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta['Timestamp'] = dt.apply(date_convert)\n",
    "mta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta = mta.sort_values(by=['Station','C/A','Scp','Timestamp'],ascending=(True, True,True, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta.reset_index(drop=True, inplace=True)\n",
    "mta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = np.array([0])\n",
    "for i in mta.index[1:len(mta.index)]:\n",
    "    if((mta.loc[i,'Station']==mta.loc[i-1,'Station']) & (mta.loc[i,'C/A']==mta.loc[i-1,'C/A']) & (mta.loc[i,'Scp']==mta.loc[i-1,'Scp'])):\n",
    "        mta.loc[i,'Entries_n'] = mta.loc[i,'Entries'] - mta.loc[i-1,'Entries']\n",
    "        mta.loc[i,'Exits_n'] = mta.loc[i,'Exits'] - mta.loc[i-1,'Exits']\n",
    "    else:\n",
    "        start_index = np.append(start_index, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in start_index:\n",
    "    mta.loc[i,'Entries_n'] = 0\n",
    "    mta.loc[i,'Exits_n'] = 0\n",
    "mta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta.loc[311990:312000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Cleaning\n",
    "### Abs\n",
    "mta['Entries_n'] = abs(mta['Entries_n'])\n",
    "mta['Exits_n'] = abs(mta['Exits_n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove extreme values\n",
    "mta = mta[(mta['Entries_n']<=10000) & (mta['Exits_n']<=10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export\n",
    "mta.to_csv('Data/MTA/MTA_ALL_RAW.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta = pd.read_csv(('Data/MTA/MTA_ALL_RAW.csv'))\n",
    "mta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Divide 4-hour intervals into 4 one-hour intervels\n",
    "time_interval = 3600\n",
    "mta.loc[:,'Exits_n'] = mta.loc[:,'Exits_n']/4\n",
    "mta.loc[:,'Entries_n'] = mta.loc[:,'Entries_n']/4\n",
    "\n",
    "mta_1 = mta.copy(deep=True)\n",
    "mta_2 = mta.copy(deep=True)\n",
    "mta_3 = mta.copy(deep=True)\n",
    "mta_1['Timestamp'] = mta_1['Timestamp'] - time_interval * 1\n",
    "mta_2['Timestamp'] = mta_2['Timestamp'] - time_interval * 2\n",
    "mta_3['Timestamp'] = mta_3['Timestamp'] - time_interval * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop Weekends\n",
    "mta = mta[(mta['Timestamp'].apply(lambda x: time.localtime(x).tm_wday)!=5) & (mta['Timestamp'].apply(lambda x: time.localtime(x).tm_wday)!=6)]\n",
    "mta = mta[(mta['Timestamp'].apply(lambda x: time.localtime(x).tm_wday)!=5) & (mta['Timestamp'].apply(lambda x: time.localtime(x).tm_wday)!=6)]\n",
    "mta = mta[(mta['Timestamp'].apply(lambda x: time.localtime(x).tm_wday)!=5) & (mta['Timestamp'].apply(lambda x: time.localtime(x).tm_wday)!=6)]\n",
    "mta = mta[(mta['Timestamp'].apply(lambda x: time.localtime(x).tm_wday)!=5) & (mta['Timestamp'].apply(lambda x: time.localtime(x).tm_wday)!=6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hour(timestamp):\n",
    "    return time.localtime(timestamp).tm_hour + round(time.localtime(timestamp).tm_min/60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta['Time_in_a_day'] = mta['Timestamp'].apply(get_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta[mta['Time_in_a_day']==24] = 0\n",
    "mta['Time_in_a_day'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta = mta.sort_values(by=['Station','C/A','Scp','Timestamp'],ascending=(True, True,True, True))\n",
    "mta.reset_index(drop=True, inplace=True)\n",
    "mta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compress the Data to Station Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_compressed = pd.DataFrame(data=None)\n",
    "for i in range(0,len(mta.index)):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_compressed = pd.DataFrame(data=None)\n",
    "for unit in mta['Unit']:\n",
    "    data = mta[mta['Unit']==unit]\n",
    "    mta_compressed['Unit'] = unit\n",
    "    for i in range (0,24):\n",
    "        mta_compressed['Entries_'+str(i)] = data[data['Time_in_a_day']==i]['Entries_n'].sum()\n",
    "        mta_compressed['Exits_'+str(i)] = data[data['Time_in_a_day']==i]['Exits_n'].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_compressed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Geo Location to the Turnstile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Link Stations\n",
    "### Thanks to Chris Whong: https://medium.com/qri-io/taming-the-mtas-unruly-turnstile-data-c945f5f96ba0\n",
    "Booth_code = pd.read_csv('Data/MTA/Stations/remote_complex_lookup.csv')\n",
    "Booth_code.columns = ['remote', 'booth', 'complex_id', 'station', 'line_name', 'division']\n",
    "Booth_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta = mta.merge(Booth_code[['remote','complex_id']], left_on='Unit', right_on='remote', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Station_data = pd.read_csv('Data/MTA/Stations/Stations.csv')\n",
    "Station_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta = mta.merge(Station_data[['Complex ID','GTFS Latitude','GTFS Longitude']], left_on='complex_id', right_on='Complex ID', how='left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gds_py_ARM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
