{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "homeless-heart",
   "metadata": {},
   "source": [
    "# Learning goals\n",
    "After this week's lesson you should be able to:\n",
    "- Refresher on data structure (DF vs Series vs List vs Array)\n",
    "- Checking a columns data types and converting types\n",
    "- Rename a (geo)dataframe column \n",
    "- parsing dates\n",
    "- slicing strings\n",
    "- handling missing data. \n",
    "    - filtering out missing data\n",
    "    - replacing missing data with the mean\n",
    "- Merging \n",
    "- More on groupby-and-summarize\n",
    "- (Defining and using a function)\n",
    "- (iterating over rows)\n",
    "- (applying a function)\n",
    "\n",
    "This week's lessons are adapted from:\n",
    "- [PPD599: Advanced Urban Analytics](https://github.com/gboeing/ppd599/tree/main/syllabus)\n",
    "- [Geo-Python Lesson 5](https://geo-python-site.readthedocs.io/en/latest/notebooks/L5/processing-data-with-pandas.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24cacc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_7/lymm6gzn0cd9kkph02m8lhsc0000gn/T/ipykernel_10993/3517648564.py:7: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "# We are going to start importing the libraries we need\n",
    "# all in one cell. \n",
    "# It is a good practice to keep all the imports in one cell so that\n",
    "# we can easily see what libraries we are using in the notebook.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3a30b2",
   "metadata": {},
   "source": [
    "# 0. Refresher\n",
    "Before we move on, let's go over the different types of data structures we've encountered so far. We are going to cover: \n",
    "- Pandas DataFrames\n",
    "- Pandas Series\n",
    "- Lists\n",
    "- Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de530ee7",
   "metadata": {},
   "source": [
    "## 0.1 Pandas: Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a1a395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa = pd.read_csv('msa_by_pop.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a103e6",
   "metadata": {},
   "source": [
    "What makes `msa` a dataframe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d63d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>MSA</th>\n",
       "      <th>population_2021_est</th>\n",
       "      <th>population_2020</th>\n",
       "      <th>perc_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-CT-PA MSA</td>\n",
       "      <td>19768458</td>\n",
       "      <td>20140470</td>\n",
       "      <td>1.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim, CA MSA</td>\n",
       "      <td>12997353</td>\n",
       "      <td>13200998</td>\n",
       "      <td>1.54%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Chicago-Naperville-Elgin, IL-IN-WI MSA</td>\n",
       "      <td>9509934</td>\n",
       "      <td>9618502</td>\n",
       "      <td>1.13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX MSA</td>\n",
       "      <td>7759615</td>\n",
       "      <td>7637387</td>\n",
       "      <td>+1.60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX MSA</td>\n",
       "      <td>7206841</td>\n",
       "      <td>7122240</td>\n",
       "      <td>+1.19%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                           MSA  population_2021_est  \\\n",
       "0     1  New York-Newark-Jersey City, NY-NJ-CT-PA MSA             19768458   \n",
       "1     2        Los Angeles-Long Beach-Anaheim, CA MSA             12997353   \n",
       "2     3        Chicago-Naperville-Elgin, IL-IN-WI MSA              9509934   \n",
       "3     4           Dallas-Fort Worth-Arlington, TX MSA              7759615   \n",
       "4     5      Houston-The Woodlands-Sugar Land, TX MSA              7206841   \n",
       "\n",
       "   population_2020 perc_change  \n",
       "0         20140470       1.85%  \n",
       "1         13200998       1.54%  \n",
       "2          9618502       1.13%  \n",
       "3          7637387      +1.60%  \n",
       "4          7122240      +1.19%  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56a09f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the type() function to see what type of object we have\n",
    "type(msa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d22cea",
   "metadata": {},
   "source": [
    "Now let's select just the `population_2020` column from `msa`. What makes the following a pandas Series? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4d601",
   "metadata": {},
   "source": [
    "## 0.2 Pandas: Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07751a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20140470\n",
       "1    13200998\n",
       "2     9618502\n",
       "3     7637387\n",
       "4     7122240\n",
       "Name: population_2020, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msa['population_2020'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "740b037a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(msa['population_2020'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bb72d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NYC        19768458\n",
       "LA         12997353\n",
       "Chicago     9509934\n",
       "Dallas      7759615\n",
       "Houston     7206841\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population = pd.Series([19768458, 12997353, 9509934, 7759615, 7206841],    \n",
    "            index=['NYC', 'LA', 'Chicago', 'Dallas', 'Houston'])\n",
    "population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "linear-danger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(population)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab3d55",
   "metadata": {},
   "source": [
    "## 0.3 Python data structures: Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2dd56e",
   "metadata": {},
   "source": [
    "Now, let's just select the values from `population` as a **list**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9ed058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a list of numbers\n",
    "## A list is a collection of objects of any type.\n",
    "## It is created by putting the objects in square brackets\n",
    "\n",
    "list1 = [19768458, 12997353, 9509934, 7759615, 7206841]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08796572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c685edb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'list' has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mlist\u001b[39;49m\u001b[39m.\u001b[39;49mmean()\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'list' has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "list.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ae10bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is also a list\n",
    "## But instead of being a list of numbers, it is a list of strings\n",
    "\n",
    "list2 = ['NYC', 'LA', 'Chicago', 'Dallas', 'Houston']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9791d10f",
   "metadata": {},
   "source": [
    "## 0.4 Numpy: Arrays\n",
    "\n",
    "We are not going to cover numpy directly in the class. But there is another list-like data structure used by the `numpy` library called an **array**. \n",
    "\n",
    "Though we are inputting a list above to create a pandas Series, pandas will turn this list into a **numpy array**. All pandas series are basically just generalized version of numpy arrays. \n",
    "\n",
    "An array is a collection of objects of the same type. It is created by putting the objects in square brackets and using the `np.array()` function. A numpy array is most used for numerical calculations such as finding the mean, min, sum of a set of values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "303144ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1_as_array = np.array(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f736fa42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19768458, 12997353,  9509934,  7759615,  7206841])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1_as_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eca61703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11448440.2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1_as_array.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d8d4e",
   "metadata": {},
   "source": [
    "# 1. Data cleaning\n",
    "As you might have already seen, when we work with data, it is not always in a shape that we can use it, sometimes column names are misspelled, there are missing values. You may also have noticed that often we can extract information from columns that might make them easier to work with. All these steps can be considered part of a data cleaning or data wrangling process, where we get the dataset ready to be used more effectively for our analysis purposes. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e11ea26",
   "metadata": {},
   "source": [
    "## 1.1 Getting the data\n",
    "Let's say we want to compare the relationship between the **total number of students in a general ed public school** to the **money spent on new school construction and improvements in that school**. \n",
    "\n",
    "### School Construction Authority\n",
    "\n",
    "First, go ahead and download the [Active Projects Under Construction](https://data.cityofnewyork.us/Housing-Development/Active-Projects-Under-Construction/8586-3zfm) dataset as a CSV and save it down to the folder where this notebook is. This is a dataset of new school projects (Capacity) and Capital Improvement Projects (CIP) currently under Construction, created by the School Construction Authority. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc074468",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we are going to read a csv directly from the web\n",
    "## We are going to use the read_csv() function from the pandas library\n",
    "## \n",
    "\n",
    "projects_under_const = pd.read_csv('Active_Projects_Under_Construction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f92c68",
   "metadata": {},
   "source": [
    "Also, go ahead and download the data dictionary `SCA Active Projects in Construction Data Dictionary.xlsx`. Data dictionaries often have explanations for what each column name represents and other useful information about the data. \n",
    "\n",
    "\n",
    "If you open up the data dictionary, does it correspond to the \"Columns in this Dataset\" section in the NYC OpenData's page on this dataset? No, right? We have to be careful about these inconsistencies, even in official portals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca503a",
   "metadata": {},
   "source": [
    "Taking a look at the first five rows we can already see there is a lot of missing data in this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c71a7250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>School Name</th>\n",
       "      <th>BoroughCode</th>\n",
       "      <th>Geographical District</th>\n",
       "      <th>Project Description</th>\n",
       "      <th>Construction Award</th>\n",
       "      <th>Project type</th>\n",
       "      <th>Building ID</th>\n",
       "      <th>Building Address</th>\n",
       "      <th>City</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>...</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Community Board</th>\n",
       "      <th>Council District</th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>BIN</th>\n",
       "      <th>BBL</th>\n",
       "      <th>NTA</th>\n",
       "      <th>Location 1</th>\n",
       "      <th>Data As Of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CAP</td>\n",
       "      <td>M777</td>\n",
       "      <td>227 WEST 27TH STREET</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAYSIDE HIGH SCHOOL - QUEENS</td>\n",
       "      <td>Q</td>\n",
       "      <td>26</td>\n",
       "      <td>FY19 RESO A AUDITORIUM UPGRADE</td>\n",
       "      <td>1261000.0</td>\n",
       "      <td>CIP</td>\n",
       "      <td>Q405</td>\n",
       "      <td>32-24 CORPORAL KENNEDY STREET</td>\n",
       "      <td>Queens</td>\n",
       "      <td>10301.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/06/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P.S. @ PARCEL F - QUEENS</td>\n",
       "      <td>Q</td>\n",
       "      <td>30</td>\n",
       "      <td>Demo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CAP</td>\n",
       "      <td>Q375</td>\n",
       "      <td>2ND STREET BETWEEN 56TH AND 57TH AVENUE</td>\n",
       "      <td>Queens</td>\n",
       "      <td>11101.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/30/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3K CENTER @ 3893 DYRE AVENUE - BRONX</td>\n",
       "      <td>X</td>\n",
       "      <td>11</td>\n",
       "      <td>Lease</td>\n",
       "      <td>6262000.0</td>\n",
       "      <td>CAP</td>\n",
       "      <td>X501</td>\n",
       "      <td>3893 DYRE AVEUNE</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/04/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P.S. 129 - QUEENS</td>\n",
       "      <td>Q</td>\n",
       "      <td>25</td>\n",
       "      <td>Addition</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CAP</td>\n",
       "      <td>Q129</td>\n",
       "      <td>128-02 7TH AVENUE</td>\n",
       "      <td>Queens</td>\n",
       "      <td>11356.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.790638</td>\n",
       "      <td>-73.839771</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>4096774.0</td>\n",
       "      <td>4.039760e+09</td>\n",
       "      <td>Whitestone</td>\n",
       "      <td>(40.790638, -73.839771)</td>\n",
       "      <td>02/06/2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            School Name BoroughCode  Geographical District  \\\n",
       "0                                   NaN           M                      2   \n",
       "1          BAYSIDE HIGH SCHOOL - QUEENS           Q                     26   \n",
       "2              P.S. @ PARCEL F - QUEENS           Q                     30   \n",
       "3  3K CENTER @ 3893 DYRE AVENUE - BRONX           X                     11   \n",
       "4                     P.S. 129 - QUEENS           Q                     25   \n",
       "\n",
       "              Project Description  Construction Award Project type  \\\n",
       "0                             NaN                 0.0          CAP   \n",
       "1  FY19 RESO A AUDITORIUM UPGRADE           1261000.0          CIP   \n",
       "2                            Demo                 0.0          CAP   \n",
       "3                           Lease           6262000.0          CAP   \n",
       "4                        Addition                 0.0          CAP   \n",
       "\n",
       "  Building ID                         Building Address       City  Postcode  \\\n",
       "0        M777                     227 WEST 27TH STREET  Manhattan       NaN   \n",
       "1        Q405            32-24 CORPORAL KENNEDY STREET     Queens   10301.0   \n",
       "2        Q375  2ND STREET BETWEEN 56TH AND 57TH AVENUE     Queens   11101.0   \n",
       "3        X501                         3893 DYRE AVEUNE      Bronx       NaN   \n",
       "4        Q129                        128-02 7TH AVENUE     Queens   11356.0   \n",
       "\n",
       "   ...   Latitude  Longitude  Community Board  Council District  Census Tract  \\\n",
       "0  ...        NaN        NaN              NaN               NaN           NaN   \n",
       "1  ...        NaN        NaN              NaN               NaN           NaN   \n",
       "2  ...        NaN        NaN              NaN               NaN           NaN   \n",
       "3  ...        NaN        NaN              NaN               NaN           NaN   \n",
       "4  ...  40.790638 -73.839771              7.0              19.0         945.0   \n",
       "\n",
       "         BIN           BBL         NTA               Location 1  Data As Of  \n",
       "0        NaN           NaN         NaN                      NaN         NaN  \n",
       "1        NaN           NaN         NaN                      NaN  01/06/2022  \n",
       "2        NaN           NaN         NaN                      NaN  10/30/2018  \n",
       "3        NaN           NaN         NaN                      NaN  08/04/2022  \n",
       "4  4096774.0  4.039760e+09  Whitestone  (40.790638, -73.839771)  02/06/2019  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects_under_const.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a817c301",
   "metadata": {},
   "source": [
    "### Class size dataset\n",
    "Also download the [2021 - 2022 Average Class Size by School](https://data.cityofnewyork.us/Education/2021-2022-Average-Class-Size-by-School/sgr7-hhwp) dataset, along with it's attachments. (Here, only `2021-2022 Average Class Size By School DD.xlsx` is the data dictoinary, the other is the dataset as an excel spreadsheet). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c150415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size = pd.read_csv('2021_-_2022_Average_Class_Size_by_School.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1585d048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBN</th>\n",
       "      <th>School Name</th>\n",
       "      <th>Grade Level</th>\n",
       "      <th>Program Type</th>\n",
       "      <th>Number of Students</th>\n",
       "      <th>Number of Classes</th>\n",
       "      <th>Average Class Size</th>\n",
       "      <th>Minimum Class Size</th>\n",
       "      <th>Maximum Class Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01M015</td>\n",
       "      <td>PS 015 ROBERTO CLEMENTE</td>\n",
       "      <td>K</td>\n",
       "      <td>G&amp;T</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>&lt;15</td>\n",
       "      <td>&lt;15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01M015</td>\n",
       "      <td>PS 015 ROBERTO CLEMENTE</td>\n",
       "      <td>K</td>\n",
       "      <td>ICT</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01M015</td>\n",
       "      <td>PS 015 ROBERTO CLEMENTE</td>\n",
       "      <td>1</td>\n",
       "      <td>G&amp;T</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>&lt;15</td>\n",
       "      <td>&lt;15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01M015</td>\n",
       "      <td>PS 015 ROBERTO CLEMENTE</td>\n",
       "      <td>1</td>\n",
       "      <td>ICT</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01M015</td>\n",
       "      <td>PS 015 ROBERTO CLEMENTE</td>\n",
       "      <td>2</td>\n",
       "      <td>G&amp;T</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>&lt;15</td>\n",
       "      <td>&lt;15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DBN              School Name Grade Level Program Type  \\\n",
       "0  01M015  PS 015 ROBERTO CLEMENTE           K          G&T   \n",
       "1  01M015  PS 015 ROBERTO CLEMENTE           K          ICT   \n",
       "2  01M015  PS 015 ROBERTO CLEMENTE           1          G&T   \n",
       "3  01M015  PS 015 ROBERTO CLEMENTE           1          ICT   \n",
       "4  01M015  PS 015 ROBERTO CLEMENTE           2          G&T   \n",
       "\n",
       "   Number of Students  Number of Classes  Average Class Size  \\\n",
       "0                  13                  1                13.0   \n",
       "1                  17                  1                17.0   \n",
       "2                   8                  1                 8.0   \n",
       "3                  18                  1                18.0   \n",
       "4                   8                  1                 8.0   \n",
       "\n",
       "  Minimum Class Size Maximum Class Size  \n",
       "0                <15                <15  \n",
       "1                 17                 17  \n",
       "2                <15                <15  \n",
       "3                 18                 18  \n",
       "4                <15                <15  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_size.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d744838",
   "metadata": {},
   "source": [
    "Here, most of the columns make sense to me. From the data dictionary, I can see that Program Type is coded as follows:\n",
    "\n",
    "- General Education (Gen Ed), \n",
    "- Integrated Co-Teaching (ICT), \n",
    "- Gifted and Talented (G&T), \n",
    "- Self-Contained (SC)\n",
    "- Accelerated (Acc)\"\n",
    "\n",
    "\n",
    "What does not make sense is the `Minimum Class Size` column, which seems to be the same as the maximum class size column in some cases. Therefore, I'll likely not use this column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c30f5eb",
   "metadata": {},
   "source": [
    "## 1.2 Assessing Data Types\n",
    "One of the next things we'll check is the data type for each column to make sure that they are in the right format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e0f61bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBN                    object\n",
       "School Name            object\n",
       "Grade Level            object\n",
       "Program Type           object\n",
       "Number of Students      int64\n",
       "Number of Classes       int64\n",
       "Average Class Size    float64\n",
       "Minimum Class Size     object\n",
       "Maximum Class Size     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_size.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac3b7b0",
   "metadata": {},
   "source": [
    "I would not necessarily change the data types for all columns (especially when there are a lot), but just the ones that you might potentially need. Here, `Maximum Class Size` is an `object` format (I'm going to ignore `Minimum Class Size` for now), likely because the size is sometimes input as `<INT` and sometimes `INT`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16d6d0b",
   "metadata": {},
   "source": [
    "## 1.3 Removing strings\n",
    "\n",
    "In order to change the data type of the min and max class size to an `int` we have to clean up those columns a little bit. \n",
    "\n",
    "The function `.replace('str_to_be_replaced','str_to_replace_with)` will take `str_to_be_replaced` and replace it with `str_to_replace_with`. Here, I'm setting `<` to be replaced by nothing which is expressed as an empty string `\"\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38621987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        15\n",
       "1        17\n",
       "2        15\n",
       "3        18\n",
       "4        15\n",
       "         ..\n",
       "12440    12\n",
       "12441    10\n",
       "12442    12\n",
       "12443    12\n",
       "12444    12\n",
       "Name: Maximum Class Size, Length: 12445, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again, I'm going to check that the function worked as expected first\n",
    "# here .str is a method that is applied to a string\n",
    "# it is a vectorized string method\n",
    "class_size['Maximum Class Size'].str.replace('<', \"\")\n",
    "\n",
    "# (Vectorization is the process of converting an algorithm from operating on a single value at a time to operating on a set of values at one time\n",
    "# but it's not super important for us to know what this is right now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5377db37",
   "metadata": {},
   "source": [
    "Now lets assign the result to a new column and why not rename the column to something in snake case. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb5a795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size['max_class_size_clean'] = class_size['Maximum Class Size'].str.replace('<', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62e1640b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBN</th>\n",
       "      <th>School Name</th>\n",
       "      <th>Grade Level</th>\n",
       "      <th>Program Type</th>\n",
       "      <th>Number of Students</th>\n",
       "      <th>Number of Classes</th>\n",
       "      <th>Average Class Size</th>\n",
       "      <th>Minimum Class Size</th>\n",
       "      <th>Maximum Class Size</th>\n",
       "      <th>max_class_size_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01M015</td>\n",
       "      <td>PS 015 ROBERTO CLEMENTE</td>\n",
       "      <td>K</td>\n",
       "      <td>G&amp;T</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>&lt;15</td>\n",
       "      <td>&lt;15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01M015</td>\n",
       "      <td>PS 015 ROBERTO CLEMENTE</td>\n",
       "      <td>K</td>\n",
       "      <td>ICT</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01M015</td>\n",
       "      <td>PS 015 ROBERTO CLEMENTE</td>\n",
       "      <td>1</td>\n",
       "      <td>G&amp;T</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>&lt;15</td>\n",
       "      <td>&lt;15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01M015</td>\n",
       "      <td>PS 015 ROBERTO CLEMENTE</td>\n",
       "      <td>1</td>\n",
       "      <td>ICT</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01M015</td>\n",
       "      <td>PS 015 ROBERTO CLEMENTE</td>\n",
       "      <td>2</td>\n",
       "      <td>G&amp;T</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>&lt;15</td>\n",
       "      <td>&lt;15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DBN              School Name Grade Level Program Type  \\\n",
       "0  01M015  PS 015 ROBERTO CLEMENTE           K          G&T   \n",
       "1  01M015  PS 015 ROBERTO CLEMENTE           K          ICT   \n",
       "2  01M015  PS 015 ROBERTO CLEMENTE           1          G&T   \n",
       "3  01M015  PS 015 ROBERTO CLEMENTE           1          ICT   \n",
       "4  01M015  PS 015 ROBERTO CLEMENTE           2          G&T   \n",
       "\n",
       "   Number of Students  Number of Classes  Average Class Size  \\\n",
       "0                  13                  1                13.0   \n",
       "1                  17                  1                17.0   \n",
       "2                   8                  1                 8.0   \n",
       "3                  18                  1                18.0   \n",
       "4                   8                  1                 8.0   \n",
       "\n",
       "  Minimum Class Size Maximum Class Size max_class_size_clean  \n",
       "0                <15                <15                   15  \n",
       "1                 17                 17                   17  \n",
       "2                <15                <15                   15  \n",
       "3                 18                 18                   18  \n",
       "4                <15                <15                   15  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_size.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc6127a",
   "metadata": {},
   "source": [
    "Now let's see if we can turn the column `min_class_size_clean` into an `integer`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "241d3def",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '>34'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m class_size[\u001b[39m'\u001b[39;49m\u001b[39mmax_class_size_clean\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mastype(\u001b[39mint\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gds_py/lib/python3.9/site-packages/pandas/core/generic.py:6240\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6233\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[1;32m   6234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[:, i]\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m   6235\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns))\n\u001b[1;32m   6236\u001b[0m     ]\n\u001b[1;32m   6238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6239\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6240\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   6241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6243\u001b[0m \u001b[39m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gds_py/lib/python3.9/site-packages/pandas/core/internals/managers.py:448\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mastype\u001b[39m(\u001b[39mself\u001b[39m: T, dtype, copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m--> 448\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gds_py/lib/python3.9/site-packages/pandas/core/internals/managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(b, f)(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gds_py/lib/python3.9/site-packages/pandas/core/internals/blocks.py:526\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    524\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[0;32m--> 526\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m    528\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    529\u001b[0m newb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gds_py/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:299\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    298\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    300\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m    301\u001b[0m     \u001b[39m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gds_py/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:230\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    227\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    229\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     values \u001b[39m=\u001b[39m astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    232\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gds_py/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:170\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mor\u001b[39;00m is_object_dtype(arr\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(dtype):\n\u001b[1;32m    169\u001b[0m     \u001b[39m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39;49mastype(dtype, copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '>34'"
     ]
    }
   ],
   "source": [
    "class_size['max_class_size_clean'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b1aaa",
   "metadata": {},
   "source": [
    "Oops, I guess we also have to replace the greater than `>`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9c476ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size['max_class_size_clean'] = class_size['max_class_size_clean'].str.replace('>', \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3acbb",
   "metadata": {},
   "source": [
    "## 1.4 Changing data types\n",
    "Now let's try to change the data type for `max_class_size_clean`. \n",
    "\n",
    "`.astype()` changes your column types for a particular column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78bad4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What I've done here is replace the old `max_class_size_clean` column with \n",
    "## a version of it that is an int\n",
    "class_size['max_class_size_clean'] = class_size['max_class_size_clean'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "add1dc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that `int` from above defaults to 64 bit integers. \n",
    "class_size['max_class_size_clean'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd50d8",
   "metadata": {},
   "source": [
    "## 1.5 Slicing strings\n",
    "\n",
    "### 1.5.1\n",
    "The `projects_under_const` has a `Data as Of` column, which gives us some temporal variation in when, at least the data was added to the table. It could be useful, for instance, if we think that `Data as Of` is a rough proxy for when the project was funded or approved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58400bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           NaN\n",
       "1    01/06/2022\n",
       "2    10/30/2018\n",
       "3    08/04/2022\n",
       "4    02/06/2019\n",
       "Name: Data As Of, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember that NaN means \"Not a Number\".\n",
    "# In other words, it is a missing value\n",
    "projects_under_const['Data As Of'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075f8efd",
   "metadata": {},
   "source": [
    "Let's say we want to extract year from these dates. We have another string-related function we can apply to all of our values under `Data As Of`. \n",
    "\n",
    "`.split()` splits strings around given separator/delimiter to create a list of strings. \n",
    "\n",
    "Here, we will use `/` as our separator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a31b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_under_const['Data As Of'].str.split('/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7be40d0",
   "metadata": {},
   "source": [
    "Now we just have to get the last value (where it exists) and create a new column with the year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a9c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [-1] is a way to access the last element of a list\n",
    "projects_under_const['data_year'] = projects_under_const['Data As Of'].str.split('/').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0075330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that when there was an NaN, the split function returned a NaN\n",
    "projects_under_const['data_year'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c4676b",
   "metadata": {},
   "source": [
    "### 1.5.2\n",
    "We will eventually be comparing school attendance characteristics to money allocated through **merging along a common column name** at the **school level**.\n",
    "\n",
    "What are out options here? Let's take  look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f247b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_under_const.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f164843",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9220b8",
   "metadata": {},
   "source": [
    "Even though there is a **School Name** column in both datasets, the format seems to be quite different. \n",
    "- For the `projects_under_const` dataset, the school names are all over the place. Some are the name and borough separated by a `-`, some also include an `@` followed by a rough locationn. \n",
    "- For the `class_size` df, the school names are consistent, but we can see that it might be a pain to match the two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_under_const['School Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd12d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size['School Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46fb71d",
   "metadata": {},
   "source": [
    "Instead, I noticed that there's a `Building ID` column in the `projects_under_constr` DF (dataframe, for short) that, though is described unhelpfully as \"ID of the Building\" in the documentation, looks to be similar to the `DBN` from `class_size` DF. In fact, when I look at what `DBN` is in the class size documentation, it says that this column \"Denotes cocatenation[sic] of district, borough and three digit school number.\"\n",
    "\n",
    "I'm going to guess here that if I extract the \"borough and three digit school number\" part of `DBN`, this will match my `Building ID` column. \n",
    "\n",
    "Thankfully, it seems like there is a fixed number of characters I need extract from `DBN`: \n",
    "- Borough = 1\n",
    "- School number = 3\n",
    "\n",
    "In total, I will need the last 4 characters from `DBN`. We'll do this again with a string splice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5204b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I am going to use the str method to get the last 4 characters of the DBN\n",
    "# within the square brackets, I am taking everything fourth from the end onwards\n",
    "# That's what -4 means\n",
    "\n",
    "class_size['DBN'].str[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35725fc9",
   "metadata": {},
   "source": [
    "Quick review of selecting ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa57e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's a little strange because backwards counting starts at -1\n",
    "\n",
    "class_size['DBN'].str[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0cedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here, 4: means that I want to start at the fifth character \n",
    "## because python starts counting at 0 for forward counting\n",
    "class_size['DBN'].str[4:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eb0356",
   "metadata": {},
   "outputs": [],
   "source": [
    "## And if I wanted to select a slice of the string in the middle\n",
    "## I can do the following\n",
    "class_size['DBN'].str[1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80fb48f",
   "metadata": {},
   "source": [
    "Back to our exericse, let's assign our slice to a new colunn called `bid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65a0a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size['bid'] = class_size['DBN'].str[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be1125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3679254",
   "metadata": {},
   "source": [
    "## 1.6 Handling missing data\n",
    "Now, let's say that our analysis depends knowing the year the data was created. There are a few ways of handling missing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781b828f",
   "metadata": {},
   "source": [
    "### 1.6.1 Removing rows \n",
    "We can remove those rows with data missing from a column that we are planning to use in our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b3b2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are going to use the isna() function to check if the data_year column has a NaN\n",
    "# isna() returns a boolean (True or False) for each row\n",
    "# and we are going to use that boolean to filter the dataframe. \n",
    "# We are going to keep only the rows where the data_year column is not a NaN\n",
    "\n",
    "projects_under_const_new = projects_under_const[projects_under_const['data_year'].isna()==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fc5697",
   "metadata": {},
   "source": [
    "### 1.6.2 Replacing missing data\n",
    "We can also replace the missing data with certain values: \n",
    "- We can replace the data with the mean of the non-NaN column values, for numerical values. (For instance, if our columns were something like \"adult heights\", then replacing the NaN with the mean values in the columns would allow us to leave the sample mean unchanged, which might be good for regression purposes). \n",
    "- We can also replace with the median (if you think there are outliers in the sample that might be skewing the mean)\n",
    "- Replacing with the mode (most frequent value) would make more sense if we think that there's some default value \n",
    "\n",
    "**What would you do here?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7b4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets the mode of the data_year column\n",
    "mode_year = projects_under_const['data_year'].mode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6442050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This fills the NaNs with the mode using the fillna() function\n",
    "# fillna() is a method that fills in missing values with a value of your choice\n",
    "projects_under_const['data_year'].fillna(mode_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write over the old data_year column with the new one\n",
    "projects_under_const['data_year'] = projects_under_const['data_year'].fillna(mode_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49012f5e",
   "metadata": {},
   "source": [
    "## Q1. In-Class Exercise 1 (5 pts)\n",
    "In the end, was it the best idea to replace the NaN data in `data_year`? Why or why not? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18228c3a",
   "metadata": {},
   "source": [
    "## 1.7 Aggregating data: A review of groupby-and-summarize\n",
    "Last week, we introduced the \"groupby-and-summarize\" operation that is very common in pandas. It's common because we often want to aggregate data by some category. For example, we might want to know the total amount of construction money allocated by school. Or we might want to know the total number of students in each school.\n",
    "\n",
    "For the projects under construction, let's group by the `Building ID`, which we had a hunch was the same as the `DBN` (Borough and School ID) to get the: \n",
    "- Total construction award amount per school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d265c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remember that .sum() will only sum the numeric columns\n",
    "projects_under_const.groupby('Building ID').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b182f9",
   "metadata": {},
   "source": [
    "Most of these columns are gibberish after we sum (for ex: we don't need a sum of latitudes and longitudes by school). Let's just select the columns we want to use: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd31d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remeber the brackets after a DF allow you to select columns\n",
    "projects_under_const.groupby('Building ID').sum()['Construction Award']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1583d7df",
   "metadata": {},
   "source": [
    "Let's assign this to a new variable name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686c1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_under_const_agg = projects_under_const.groupby('Building ID').sum()['Construction Award']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac6f1a3",
   "metadata": {},
   "source": [
    "Here you can see that the result is a **pandas Series**. To make this easier to work with during the merge, let's transform this into a pandas DF. \n",
    "\n",
    "I'm going to use a function call `.reset_index()` as a trick to do this. `.reset_index()` is a method that resets the index of a dataframe to a column of your choice. The default is to reset the index to a column of sequential numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d27ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how Building ID, which was the index before, is now a column. \n",
    "# and the index is i just 0,...,1180\n",
    "\n",
    "projects_under_const_agg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992be19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_under_const_agg = projects_under_const_agg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_under_const_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835da52b",
   "metadata": {},
   "source": [
    "Let's do something similar with the `class_size` df. As we can see from the below, our data is likely one row per grade and program. We want to aggregate this to the school level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42dff8f",
   "metadata": {},
   "source": [
    "I'm first going to filter my DF since I just want 'Gen Ed' in order not to skew the representative class size by special programs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d0be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .unique() returns a list of all the unique values in a column\n",
    "class_size['Program Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dce9926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am going to use the == operator to check if the value in the Program Type column is equal to 'Gen Ed'\n",
    "# Then we'll set this filtered dataframe to a new variable\n",
    "# and use that new dataframe from now on. \n",
    "class_size_new = class_size[class_size['Program Type']=='Gen Ed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db69ba",
   "metadata": {},
   "source": [
    "Now, to get the total number of students in each school, I'll have to: \n",
    "- Multiply `Number of Classes` and `Number of Students` (let's assume this is per class)\n",
    "- Sum the total number of students across all classes in a school. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b0347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size_new['total_students_in_grade'] = class_size_new['Number of Students'] * class_size_new['Number of Classes']\n",
    "# Yes, ignore the SettingWithCopyWarning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e5abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b52442c",
   "metadata": {},
   "source": [
    "Now let's groupby `bid` and sum all the grades within each school. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d43db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size_new.groupby('bid').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50765542",
   "metadata": {},
   "source": [
    "Again, we'll just need the `total_students_in_grade` column here. And I'm going to do the `reset_index()` trick again. This time, I'm going to string all these steps together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a8343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas reads this code from left to right and will apply each function on the right to the everything on the left\n",
    "# So, first we are going to group by bid\n",
    "# Then we are going to sum each group\n",
    "# Then from the entire summed dataframe, we are going to select the total_students_in_grade column\n",
    "# Selecting that series, we are going to reset the index to create our new dataframe. .\n",
    "\n",
    "class_size_new_agg = class_size_new.groupby('bid').sum()['total_students_in_grade'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed44186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size_new_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4b6ef1",
   "metadata": {},
   "source": [
    "Finally, we get to do our merge. We are going to merge \n",
    "- `projects_under_cont_agg`\n",
    "- `class_size_new_agg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdad3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size_new_agg.merge(projects_under_const_agg,left_on='bid',right_on='Building ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ba06c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = class_size_new_agg.merge(projects_under_const_agg,left_on='bid',right_on='Building ID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624b39cf",
   "metadata": {},
   "source": [
    "Ok, finally, to get to our answer, we're going to apply the `.corr()` function to our dataframe. The [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) tells us that this function computes pairwise correlation of columns, excluding NA/null values.\n",
    "\n",
    "The default method is a 'Pearson' correlation, with all methods being: \n",
    "- pearson : standard correlation coefficient\n",
    "- kendall : Kendall Tau correlation coefficient\n",
    "- spearman : Spearman rank correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e9a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yikes, 0.079 correlation. I guess I assumed wrong that there would be an strong correlation between the number of students in a school and the amount of money spent on construction.\n",
    "merged_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4d00ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a rank correlation instead of a linear correlation hasn't improved the correlation much.\n",
    "# (Don't worry about what this is right now.)\n",
    "merged_df.corr(method = 'spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5df030",
   "metadata": {},
   "source": [
    "This was a long lecture, no more exercises!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gds_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "672b62ada503359a2e29deaf97e4d900f2af6bdd788748d1dd051bc8914148d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
